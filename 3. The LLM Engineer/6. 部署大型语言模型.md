## å¤§è§„æ¨¡éƒ¨ç½²LLMæ˜¯ä¸€ä¸ªå¯èƒ½éœ€è¦å¤šä¸ªGPUé›†ç¾¤çš„å·¥ç¨‹
åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œæ¼”ç¤ºå’Œæœ¬åœ°åº”ç”¨ç¨‹åºå¯ä»¥ä»¥ä½å¾—å¤šçš„å¤æ‚åº¦å®ç°

* **Local deployment**: éšç§æ˜¯å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ç›¸è¾ƒäºç§æœ‰æ¨¡å‹çš„é‡è¦ä¼˜åŠ¿ã€‚æœ¬åœ°LLMæœåŠ¡å™¨ï¼ˆå¦‚[LM Studio](https://lmstudio.ai/)ã€[Ollama](https://ollama.ai/)ã€[oobabooga](https://github.com/oobabooga/text-generation-webui)ã€[kobold.cpp](https://github.com/LostRuins/koboldcpp)ç­‰ï¼‰åˆ©ç”¨è¿™ä¸€ä¼˜åŠ¿ä¸ºæœ¬åœ°åº”ç”¨ç¨‹åºæä¾›æ”¯æŒ 
* **Demo deployment**: åƒ[Gradio](https://www.gradio.app/)å’Œ[Streamlit](https://docs.streamlit.io/)è¿™æ ·çš„æ¡†æ¶æœ‰åŠ©äºåŸå‹è®¾è®¡åº”ç”¨ç¨‹åºå’Œåˆ†äº«æ¼”ç¤ºã€‚æ‚¨è¿˜å¯ä»¥è½»æ¾åœ°å°†å®ƒä»¬æ‰˜ç®¡åœ¨çº¿ä¸Šï¼Œä¾‹å¦‚ä½¿ç”¨[Hugging Face Spaces](https://huggingface.co/spaces)
* **Server deployment**: å¤§è§„æ¨¡éƒ¨ç½²LLMéœ€è¦äº‘ï¼ˆå¦è§[SkyPilot](https://skypilot.readthedocs.io/en/latest/)ï¼‰æˆ–æœ¬åœ°åŸºç¡€è®¾æ–½ï¼Œå¹¶ç»å¸¸åˆ©ç”¨ä¼˜åŒ–çš„æ–‡æœ¬ç”Ÿæˆæ¡†æ¶ï¼Œå¦‚[TGI](https://github.com/huggingface/text-generation-inference)ã€[vLLM](https://github.com/vllm-project/vllm/tree/main)ç­‰
* **Edge deployment**: åœ¨å—é™ç¯å¢ƒä¸‹ï¼Œé«˜æ€§èƒ½æ¡†æ¶å¦‚[MLC LLM](https://github.com/mlc-ai/mlc-llm)å’Œ[mnn-llm](https://github.com/wangzhaode/mnn-llm/blob/master/README_en.md)å¯ä»¥åœ¨ç½‘é¡µæµè§ˆå™¨ã€Androidå’ŒiOSä¸Šéƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ 

* ğŸ“š **æ¨èè¯¾ç¨‹**:
* [Streamlit - Build a basic LLM app](https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps): ä½¿ç”¨Streamlitåˆ›å»ºåŸºæœ¬çš„ç±»ä¼¼ChatGPTåº”ç”¨ç¨‹åºçš„æ•™ç¨‹
* [HF LLM Inference Container](https://huggingface.co/blog/sagemaker-huggingface-llm): åœ¨Amazon SageMakerä¸Šä½¿ç”¨Hugging Faceçš„æ¨ç†å®¹å™¨éƒ¨ç½²LLM
* [PhilschmidÂ blog](https://www.philschmid.de/) by Philipp Schmid: å…³äºä½¿ç”¨Amazon SageMakeréƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹çš„é«˜è´¨é‡æ–‡ç« é›†åˆ
* [Optimizing latence](https://hamel.dev/notes/llm/inference/03_inference.html) by Hamel Husain: åœ¨ååé‡å’Œå»¶è¿Ÿæ–¹é¢çš„TGIã€vLLMã€CTranslate2å’Œmlcçš„æ¯”è¾ƒ 




